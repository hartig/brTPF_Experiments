#!/usr/bin/env node
/*! @license ©2013 Ruben Verborgh - Multimedia Lab / iMinds / Ghent University */
/* Command-line utility to execute SPARQL queries over triple pattern fragments. */

var ldf = require('../../../Client.js/ldf-client');

// Retrieve and check arguments
var args = require('minimist')(process.argv.slice(2));
if (args.listformats)
  return Object.keys(ldf.SparqlResultWriter.writers).forEach(function (t) { console.log(t); });
if (!(args.q || args.f) && args._.length < 1 || args._.length > 2 || args.h || args.help) {
  console.error('usage: ldf-client [startFragment] query.sparql [-c config.json] ' +
                                  '[-t application/json] [-l logLevel] [--help] ' +
                                  '[--outputFileNumber y] [--timeoutInMins t]');
  console.error('       ldf-client --listformats (Lists supported result formats for -t)');
  return process.exit(1);
}

// Load main libraries (postponed as to here for speed)
var fs = require('fs'),
    path = require('path'),
    N3 = require('n3'),
    Logger = ldf.Logger;

// Parse and initialize configuration
var configFile = args.c ? args.c : path.join(__dirname, '../config-default.json'),
    config = JSON.parse(fs.readFileSync(configFile, { encoding: 'utf8' })),
    queryFile = args.f || args.q || args._.pop(),
    startFragment = args._.pop() || config.startFragment,
    query = args.q || (args.f || fs.existsSync(queryFile) ? fs.readFileSync(queryFile, 'utf8') : queryFile),
    mimeType = args.t || 'application/json';

// Configure logging
var logname = 'eval_TPF_' + args.outputFileNumber + '.csv';
Logger.setLevel(args.l || 'warning');

function queryNameForMeasurementsFile( filepath ) {
  var arr = filepath.split("/");
  var filename = arr[arr.length - 1];
  if ( filename.length > 3 && filename.substring(filename.length-3)==".rq" )
    return filename.slice(0, -3);
  else
    return filename;
}

var start = new Date();
var DEBUGfirstTime, DEBUGtime, DEBUGfirstHttp, DEBUGhttp, DEBUGdata, DEBUGtotal = 0;

var timeoutInMins = args.timeoutInMins ? args.timeoutInMins : 5;

setTimeout( function () {
  DEBUGtime = new Date() - start;
  DEBUGhttp = config.fragmentsClient._httpClient.DEBUGcalls;
  DEBUGtps = config.fragmentsClient._numberOfTriplePatternsInQuery;
  DEBUGdata = config.fragmentsClient._overallNumberOfTriplesReceived;
  queryName = queryNameForMeasurementsFile(queryFile);
  fs.appendFileSync(logname, [queryName,DEBUGtps,DEBUGfirstTime, DEBUGfirstHttp, DEBUGtime, DEBUGhttp, DEBUGdata, DEBUGtotal, 'TIMEOUT', timeoutInMins].join(',') + '\n');
  process.exit();
}, timeoutInMins*60*1000 );

// Execute the query and output its results
config.fragmentsClient = new ldf.FragmentsClient(startFragment, config);
try {
  var sparqlIterator = new ldf.SparqlIterator(query, config), writer;
  switch (sparqlIterator.queryType) {
  // Write JSON representations of the rows or boolean
  case 'ASK':
  case 'SELECT':
    writer = new ldf.SparqlResultWriter(mimeType, sparqlIterator);
    writer.on('data', function (data) {
      if (data.length > 3)
        DEBUGtotal++;
      if (!DEBUGfirstTime && data.length > 3) {
        DEBUGfirstTime = new Date() - start;
        DEBUGfirstHttp = config.fragmentsClient._httpClient.DEBUGcalls;
      }
//      process.stdout.write(data);
    });
    break;
  // Write an RDF representation of all results
  case 'CONSTRUCT':
  case 'DESCRIBE':
    writer = new N3.Writer(process.stdout, config);
    sparqlIterator.on('data', function (triple) { writer.addTriple(triple); })
                  .on('end',  function () { writer.end(); });
    break;
  default:
    throw new ldf.SparqlIterator.UnsupportedQueryError(query);
  }

  // Report an error's stack trace
  sparqlIterator.on('error', function (error) {
    console.error('ERROR: An error occured during query execution.\n');
    console.error(error.stack);
    DEBUGtime = new Date() - start;
    DEBUGhttp = config.fragmentsClient._httpClient.DEBUGcalls;
    DEBUGtps = config.fragmentsClient._numberOfTriplePatternsInQuery;
    DEBUGdata = config.fragmentsClient._overallNumberOfTriplesReceived;
    queryName = queryNameForMeasurementsFile(queryFile);
    fs.appendFileSync(logname, [queryName,DEBUGtps,DEBUGfirstTime, DEBUGfirstHttp, DEBUGtime, DEBUGhttp, DEBUGdata, DEBUGtotal, 'ERROR', error].join(',') + '\n');
    process.exit();
  });

  writer.on('end', function () {
    DEBUGtime = new Date() - start;
    DEBUGhttp = config.fragmentsClient._httpClient.DEBUGcalls;
    DEBUGtps = config.fragmentsClient._numberOfTriplePatternsInQuery;
    DEBUGdata = config.fragmentsClient._overallNumberOfTriplesReceived;
    queryName = queryNameForMeasurementsFile(queryFile);
    fs.appendFileSync(logname, [queryName,DEBUGtps,DEBUGfirstTime, DEBUGfirstHttp, DEBUGtime, DEBUGhttp, DEBUGdata, DEBUGtotal].join(',') + '\n');
// I commented the following line as flush() does not seem to be
// supported in newer node.js version anymore.
//                                         -Olaf
    //process.stdout.flush();
// Instead, the process has to be terminated now. Hence, I added
// the following line.
//                                         -Olaf
    process.exit();
  });
}
// Report a synchronous error
catch (error) {
  console.error('ERROR: Query execution could not start.\n');
  switch (error.name) {
  case 'InvalidQueryError':
  case 'UnsupportedQueryError':
    console.error(error.message);
    break;
  default:
    console.error(error.stack);
  }
}
